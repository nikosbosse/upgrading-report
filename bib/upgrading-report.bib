
@article{claeskensForecastCombinationPuzzle2016,
  title = {The Forecast Combination Puzzle: {{A}} Simple Theoretical Explanation},
  shorttitle = {The Forecast Combination Puzzle},
  author = {Claeskens, Gerda and Magnus, Jan R. and Vasnev, Andrey L. and Wang, Wendun},
  date = {2016-07},
  journaltitle = {International Journal of Forecasting},
  shortjournal = {International Journal of Forecasting},
  volume = {32},
  pages = {754--762},
  issn = {01692070},
  doi = {10.1016/j.ijforecast.2015.12.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207016000327},
  urldate = {2021-07-02},
  abstract = {This paper offers a theoretical explanation for the stylized fact that forecast combinations with estimated optimal weights often perform poorly in applications. The properties of the forecast combination are typically derived under the assumption that the weights are fixed, while in practice they need to be estimated. If the fact that the weights are random rather than fixed is taken into account during the optimality derivation, then the forecast combination will be biased (even when the original forecasts are unbiased), and its variance will be larger than in the fixed-weight case. In particular, there is no guarantee that the ‘optimal’ forecast combination will be better than the equal-weight case, or even improve on the original forecasts. We provide the underlying theory, some special cases, and a numerical illustration.},
  file = {/mnt/data/Google Drive/Zotero/storage/4TUUCQXG/Claeskens et al. - 2016 - The forecast combination puzzle A simple theoreti.pdf},
  langid = {english},
  number = {3}
}

@online{evanl.rayChallengesTrainingEnsembles,
  title = {Challenges in Training Ensembles to Forecast {{COVID}}-19 Cases and Deaths in the {{United States}} - {{International Institute}} of {{Forecasters}}},
  author = {{Evan L. Ray} and {Logan C. Brooks} and {Jacob Bien} and {Johannes Bracher} and {Aaron Gerding} and {Aaron Rumack} and {Matthew Biggerstaff} and {Michael A. Johansson} and {Ryan J. Tibshirani} and {Nicholas G. Reich}},
  url = {https://forecasters.org/blog/2021/04/09/challenges-in-training-ensembles-to-forecast-covid-19-cases-and-deaths-in-the-united-states/},
  urldate = {2021-07-12},
  file = {/mnt/data/Google Drive/Zotero/storage/LQVPJLRR/challenges-in-training-ensembles-to-forecast-covid-19-cases-and-deaths-in-the-united-states.html},
  langid = {american}
}

@article{gneitingCalibratedProbabilisticForecasting2005,
  title = {Calibrated {{Probabilistic Forecasting Using Ensemble Model Output Statistics}} and {{Minimum CRPS Estimation}}},
  author = {Gneiting, Tilmann and Raftery, Adrian E. and Westveld, Anton H. and Goldman, Tom},
  date = {2005-05-01},
  journaltitle = {Monthly Weather Review},
  shortjournal = {Mon. Wea. Rev.},
  volume = {133},
  pages = {1098--1118},
  publisher = {{American Meteorological Society}},
  issn = {0027-0644},
  doi = {10.1175/MWR2904.1},
  url = {https://journals.ametsoc.org/mwr/article/133/5/1098/67504/Calibrated-Probabilistic-Forecasting-Using},
  urldate = {2020-08-12},
  file = {/mnt/data/Google Drive/Zotero/storage/DWIEDUKB/Gneiting et al. - 2005 - Calibrated Probabilistic Forecasting Using Ensembl.pdf;/mnt/data/Google Drive/Zotero/storage/UKQZH4WN/Calibrated-Probabilistic-Forecasting-Using.html},
  langid = {english},
  number = {5}
}

@article{heldProbabilisticForecastingInfectious2017c,
  title = {Probabilistic Forecasting in Infectious Disease Epidemiology: The 13th {{Armitage}} Lecture: {{L}}. {{HELD}}, {{S}}. {{MEYER AND J}}. {{BRACHER}}},
  shorttitle = {Probabilistic Forecasting in Infectious Disease Epidemiology},
  author = {Held, Leonhard and Meyer, Sebastian and Bracher, Johannes},
  date = {2017-09-30},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  volume = {36},
  pages = {3443--3460},
  issn = {02776715},
  doi = {10.1002/sim.7363},
  url = {http://doi.wiley.com/10.1002/sim.7363},
  urldate = {2019-09-21},
  file = {/mnt/data/Google Drive/Zotero/storage/4GBAAE6J/Held et al. - 2017 - Probabilistic forecasting in infectious disease ep.pdf},
  langid = {english},
  number = {22}
}

@article{leutbecherEnsembleSizeHow2019,
  title = {Ensemble Size: {{How}} Suboptimal Is Less than Infinity?},
  shorttitle = {Ensemble Size},
  author = {Leutbecher, Martin},
  date = {2019},
  journaltitle = {Quarterly Journal of the Royal Meteorological Society},
  volume = {145},
  pages = {107--128},
  issn = {1477-870X},
  doi = {10.1002/qj.3387},
  url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3387},
  urldate = {2021-07-05},
  abstract = {Ensemble forecasts are the method of choice in numerical weather prediction (NWP) to generate probabilistic forecasts. The number of members in an ensemble is an important factor in determining how well a probability distribution of a weather-related variable can be estimated. Having only a finite number of members reduces the average skill such a probabilistic forecast can have. Increasing ensemble size is therefore desirable; however, ensemble size is also proportional to the computational cost. Having a small ensemble size limits the cost and makes other improvements, such as increases in spatial resolution, feasible. This article examines how average skill measures with metrics such as the continuous ranked probability score, the quantile score, and the Dawid–Sebastiani score converge with ensemble size. A numerical experiment with a 200 member ensemble using the European Centre for Medium-Range Weather Forecasts (ECMWF) Integrated Forecasting System (IFS) model at a resolution of 29 km and a forecast range of 15 days provides data to compare the convergence of probabilistic skill in a current NWP system with theoretical expectations derived for perfectly reliable ensembles with exchangeable members. Results in the first part of the article can help users of operational NWP ensemble forecasts formulate their minimum requirement in terms of ensemble size. In the second part, requirements for scientists who test changes to NWP systems are examined. Using proper scores and fair scores, it is explored whether testing changes in the ensemble forecasts can be meaningful with fewer members than in the operational configuration. Results are based on medium-range numerical experiments with 50 members. Two experiments test the activation of a representation of model uncertainty and three other experiments test changes in horizontal resolution from 29 to 18 km and from 29 to 45 km.},
  annotation = {\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3387},
  file = {/mnt/data/Google Drive/Zotero/storage/5S7BT4E4/Leutbecher - 2019 - Ensemble size How suboptimal is less than infinit.pdf;/mnt/data/Google Drive/Zotero/storage/GNK8ZM9M/qj.html},
  keywords = {ensemble size,ensembles,fair score,forecast verification,forecasting,numerical weather prediction,proper scoring rule},
  langid = {english},
  number = {S1}
}

@online{loganc.brooksComparingEnsembleApproaches,
  title = {Comparing Ensemble Approaches for Short-Term Probabilistic {{COVID}}-19 Forecasts in the {{U}}.{{S}}. - {{International Institute}} of {{Forecasters}}},
  author = {{Logan C. Brooks} and {Evan L. Ray} and {Jacob Bien} and {Johannes Bracher} and {Aaron Rumack} and {Ryan J. Tibshirani} and {Nicholas G. Reich}},
  url = {https://forecasters.org/blog/2020/10/28/comparing-ensemble-approaches-for-short-term-probabilistic-covid-19-forecasts-in-the-u-s/},
  urldate = {2021-07-12},
  file = {/mnt/data/Google Drive/Zotero/storage/UCPVDFPE/comparing-ensemble-approaches-for-short-term-probabilistic-covid-19-forecasts-in-the-u-s.html},
  langid = {american}
}


